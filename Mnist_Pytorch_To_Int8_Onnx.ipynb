{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNRbf869kSbjmUSl7wAxQBm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rrankawat/stm32/blob/main/Mnist_Pytorch_To_Int8_Onnx.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install onnx onnxruntime onnxscript onnxruntime-tools"
      ],
      "metadata": {
        "id": "WKWZfTfskJXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZfzVc-Nhw_7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ONNX + ORT quantization\n",
        "import onnx\n",
        "import onnxruntime as ort\n",
        "\n",
        "from onnxruntime.quantization import quantize_dynamic, QuantType, QuantFormat, CalibrationDataReader"
      ],
      "metadata": {
        "id": "9ZN1aiFGiTTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# Model\n",
        "# -----------------------\n",
        "class MNISTTinyCNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 6, 3, 1) # 28 -> 26\n",
        "    self.conv2 = nn.Conv2d(6, 16, 3, 1) # 13 -> 11\n",
        "    self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "    self.fc2 = nn.Linear(120, 84)\n",
        "    self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = F.max_pool2d(x, 2) # 28 -> 14\n",
        "\n",
        "    x = F.relu(self.conv2(x))\n",
        "    x = F.max_pool2d(x, 2) # 14 -> 7\n",
        "\n",
        "    x = torch.flatten(x, 1)\n",
        "\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x) # logits\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "udq2NlbAlSPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# Utils\n",
        "# -----------------------\n",
        "def total_time_minutes(start_time):\n",
        "  return (time.time() - start_time) / 60\n",
        "\n",
        "def get_loaders(batch_size=64):\n",
        "  transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "  train_transform = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "  test_transform = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "  train_loader = DataLoader(train_transform, batch_size=batch_size, shuffle=True)\n",
        "  test_loader = DataLoader(test_transform, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "  return train_loader, test_loader"
      ],
      "metadata": {
        "id": "3hqPQK0coU0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# Training\n",
        "# -----------------------\n",
        "def train(epoch, model, train_loader, criterian, optimizer, log_every=600):\n",
        "  model.train()\n",
        "  trn_corr = 0\n",
        "  last_loss = None\n",
        "\n",
        "  for b, (X_train, y_train) in enumerate(train_loader):\n",
        "    y_pred = model(X_train)\n",
        "    loss = criterian(y_pred, y_train)\n",
        "    last_loss = loss.item()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    predicted = y_pred.argmax(dim=1)\n",
        "    trn_corr += (predicted == y_train).sum().item()\n",
        "\n",
        "    if b % log_every == 0:\n",
        "      seen = b * len(X_train)\n",
        "      total = len(train_loader.dataset)\n",
        "      pct = 100.0 * b / len(train_loader)\n",
        "      print(f\"Epoch {epoch+1} [{seen}/{total} ({pct:.0f}%)]  Loss: {last_loss:.6f}\")\n",
        "\n",
        "  tran_acc = trn_corr / len(train_loader.dataset)\n",
        "  return last_loss, tran_acc"
      ],
      "metadata": {
        "id": "IaoMHa-ZownB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# Testing\n",
        "# -----------------------\n",
        "def test(model, test_loader, criterian):\n",
        "  model.eval()\n",
        "  test_corr = 0\n",
        "  total_loss = 0\n",
        "  total = 0\n",
        "\n",
        "  for X_test, y_test in test_loader:\n",
        "    y_val = model(X_test)\n",
        "    loss = criterian(y_val, y_test)\n",
        "\n",
        "    total_loss += loss.item() * y_test.size(0)\n",
        "    total += y_test.size(0)\n",
        "\n",
        "    predicted = y_val.argmax(dim=1)\n",
        "    test_corr += (predicted == y_test).sum().item()\n",
        "\n",
        "  test_loss = total_loss / total\n",
        "  test_acc = test_corr / total\n",
        "\n",
        "  return test_loss, test_acc"
      ],
      "metadata": {
        "id": "hH4Pknv5iCGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "# -----------------------\n",
        "# ONNX + INT8\n",
        "# -----------------------\n",
        "def export_onnx(model, onnx_path):\n",
        "  model.eval()\n",
        "\n",
        "  dummy = torch.randn(1, 1, 28, 28)\n",
        "  torch.onnx.export(\n",
        "        model,\n",
        "        dummy,\n",
        "        onnx_path,\n",
        "        input_names=[\"input\"],\n",
        "        output_names=[\"logits\"],\n",
        "        opset_version=13,\n",
        "        do_constant_folding=True,\n",
        "        dynamic_axes={\"input\": {0: \"batch\"}, \"logits\": {0: \"batch\"}},\n",
        "    )\n",
        "  onnx.checker.check_model(onnx_path)\n",
        "  print(f\"ONNX model saved to: {onnx_path}\")\n",
        "\n",
        "def quantize_onnx_dynamic(fp32_path, int8_path):\n",
        "  quantize_dynamic(\n",
        "      model_input=fp32_path,\n",
        "      model_output=int8_path,\n",
        "      weight_type=QuantType.QUInt8,\n",
        "      extra_options={\"DisableShapeInference\": True}\n",
        "    )\n",
        "  print(f\"INT8 model saved to: {int8_path}\")\n",
        "\n",
        "def ort_sanity_check(onnx_path):\n",
        "  sess = ort.InferenceSession(onnx_path, providers=['CPUExecutionProvider'])\n",
        "  input_name = sess.get_inputs()[0].name\n",
        "  x = np.random.rand(1, 1, 28, 28).astype(np.float32)\n",
        "  out = sess.run(None, {input_name: x})[0]\n",
        "  print(\"ORT run output shape: \", out.shape)"
      ],
      "metadata": {
        "id": "PBGQPibLzqBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# Main\n",
        "# -----------------------\n",
        "def main():\n",
        "  torch.manual_seed(41)\n",
        "\n",
        "  train_loader, test_loader = get_loaders(batch_size=64)\n",
        "\n",
        "  model = MNISTTinyCNN()\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "  epochs = 5\n",
        "  train_losses, train_accs = [], []\n",
        "  test_losses, test_accs = [], []\n",
        "\n",
        "  start_time = time.time()\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    train_loss, train_acc = train(epoch, model, train_loader, criterion, optimizer)\n",
        "    test_loss, test_acc = test(model, test_loader, criterion)\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    train_accs.append(train_acc)\n",
        "    test_losses.append(test_loss)\n",
        "    test_accs.append(test_acc)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.4f}\")\n",
        "\n",
        "  print(f\"Time taken: {total_time_minutes(start_time)} minutes!\")\n",
        "\n",
        "  # Export + quantize for STM32 pipeline\n",
        "  fp32_onnx = \"mnist_lenet_fp32.onnx\"\n",
        "  int8_onnx = \"minst_lenet_int8.onnx\"\n",
        "\n",
        "  export_onnx(model, fp32_onnx)\n",
        "  quantize_onnx_dynamic(fp32_onnx, int8_onnx)\n",
        "  ort_sanity_check(int8_onnx)\n",
        "\n",
        "  print(\"STM32 pipeline is ready\", fp32_onnx, int8_onnx)"
      ],
      "metadata": {
        "id": "qmTadosW0YZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "  main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Q9gwvRlt4MVo",
        "outputId": "b677eb3e-2b4e-4fcd-b768-de542e8f70b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 [0/60000 (0%)]  Loss: 2.307117\n",
            "Epoch 1 [38400/60000 (64%)]  Loss: 0.090759\n",
            "Epoch 1/5 | Train Loss: 0.1874 | Train Acc: 0.8975 | Test Loss: 0.1055 | Test Acc: 0.9670\n",
            "Epoch 2 [0/60000 (0%)]  Loss: 0.104839\n",
            "Epoch 2 [38400/60000 (64%)]  Loss: 0.103755\n",
            "Epoch 2/5 | Train Loss: 0.1431 | Train Acc: 0.9706 | Test Loss: 0.0688 | Test Acc: 0.9779\n",
            "Epoch 3 [0/60000 (0%)]  Loss: 0.061737\n",
            "Epoch 3 [38400/60000 (64%)]  Loss: 0.029547\n",
            "Epoch 3/5 | Train Loss: 0.1530 | Train Acc: 0.9784 | Test Loss: 0.0572 | Test Acc: 0.9815\n",
            "Epoch 4 [0/60000 (0%)]  Loss: 0.019009\n",
            "Epoch 4 [38400/60000 (64%)]  Loss: 0.070435\n",
            "Epoch 4/5 | Train Loss: 0.0505 | Train Acc: 0.9832 | Test Loss: 0.0486 | Test Acc: 0.9826\n",
            "Epoch 5 [0/60000 (0%)]  Loss: 0.023014\n",
            "Epoch 5 [38400/60000 (64%)]  Loss: 0.071698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2942998175.py:17: UserWarning: # 'dynamic_axes' is not recommended when dynamo=True, and may lead to 'torch._dynamo.exc.UserError: Constraints violated.' Supply the 'dynamic_shapes' argument instead if export is unsuccessful.\n",
            "  torch.onnx.export(\n",
            "W1226 23:32:09.919000 641 torch/onnx/_internal/exporter/_compat.py:114] Setting ONNX exporter to use operator set version 18 because the requested opset_version 13 is a lower version than we have implementations for. Automatic version conversion will be performed, which may not be successful at converting to the requested version. If version conversion is unsuccessful, the opset version of the exported model will be kept at 18. Please consider setting opset_version >=18 to leverage latest ONNX features\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5 | Train Loss: 0.0027 | Train Acc: 0.9862 | Test Loss: 0.0396 | Test Acc: 0.9876\n",
            "Time taken: 1.9165327350298564 minutes!\n",
            "[torch.onnx] Obtain model graph for `MNISTTinyCNN([...]` with `torch.export.export(..., strict=False)`...\n",
            "[torch.onnx] Obtain model graph for `MNISTTinyCNN([...]` with `torch.export.export(..., strict=False)`... ✅\n",
            "[torch.onnx] Run decomposition...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:onnxscript.version_converter:The model version conversion is not supported by the onnxscript version converter and fallback is enabled. The model will be converted using the onnx C API (target version: 13).\n",
            "WARNING:onnxscript.version_converter:Failed to convert the model to the target version 13 using the ONNX C API. The model was not modified\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/onnxscript/version_converter/__init__.py\", line 127, in call\n",
            "    converted_proto = _c_api_utils.call_onnx_api(\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/onnxscript/version_converter/_c_api_utils.py\", line 65, in call_onnx_api\n",
            "    result = func(proto)\n",
            "             ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/onnxscript/version_converter/__init__.py\", line 122, in _partial_convert_version\n",
            "    return onnx.version_converter.convert_version(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/onnx/version_converter.py\", line 39, in convert_version\n",
            "    converted_model_str = C.convert_version(model_str, target_version)\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: /github/workspace/onnx/version_converter/BaseConverter.h:68: adapter_lookup: Assertion `false` failed: No Adapter From Version $15 for Shape\n",
            "WARNING:root:Please consider to run pre-processing before quantization. Refer to example: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[torch.onnx] Run decomposition... ✅\n",
            "[torch.onnx] Translate the graph into ONNX...\n",
            "[torch.onnx] Translate the graph into ONNX... ✅\n",
            "Applied 1 of general pattern rewrite rules.\n",
            "ONNX model saved to: mnist_lenet_fp32.onnx\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InferenceError",
          "evalue": "[ShapeInferenceError] Inferred shape and existing shape differ in dimension 0: (400) vs (120)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInferenceError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1451076590.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-2253917252.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m   \u001b[0mexport_onnx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp32_onnx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m   \u001b[0mquantize_onnx_dynamic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp32_onnx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint8_onnx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m   \u001b[0mort_sanity_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint8_onnx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2942998175.py\u001b[0m in \u001b[0;36mquantize_onnx_dynamic\u001b[0;34m(fp32_path, int8_path)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mquantize_onnx_dynamic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp32_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint8_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m   quantize_dynamic(\n\u001b[0m\u001b[1;32m     32\u001b[0m       \u001b[0mmodel_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfp32_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m       \u001b[0mmodel_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint8_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/onnxruntime/quantization/quantize.py\u001b[0m in \u001b[0;36mquantize_dynamic\u001b[0;34m(model_input, model_output, op_types_to_quantize, per_channel, reduce_range, weight_type, nodes_to_quantize, nodes_to_exclude, use_external_data_format, extra_options)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_opset_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m     quantizer = ONNXQuantizer(\n\u001b[0m\u001b[1;32m    878\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mper_channel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/onnxruntime/quantization/onnx_quantizer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, per_channel, reduce_range, mode, static, weight_qType, activation_qType, tensors_range, nodes_to_quantize, nodes_to_exclude, op_types_to_quantize, extra_options)\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace_gemm_with_matmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;31m# We need to update value_infos.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_and_reload_model_with_shape_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_infos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mvi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_info\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_infos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mot\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/onnxruntime/quantization/quant_utils.py\u001b[0m in \u001b[0;36msave_and_reload_model_with_shape_infer\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m   1031\u001b[0m         \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquant_tmp_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoinpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model.onnx\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_copy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_posix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_as_external_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1033\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_with_shape_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1034\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/onnxruntime/quantization/quant_utils.py\u001b[0m in \u001b[0;36mload_model_with_shape_infer\u001b[0;34m(model_path)\u001b[0m\n\u001b[1;32m   1019\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_model_with_shape_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mModelProto\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0minferred_model_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_identified_filename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"-inferred\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m     \u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_inference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_shapes_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minferred_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minferred_model_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_posix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0madd_infer_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/onnx/shape_inference.py\u001b[0m in \u001b[0;36minfer_shapes_path\u001b[0;34m(model_path, output_path, check_type, strict_mode, data_prop)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutput_path\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0moutput_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m     \u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_shapes_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_prop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInferenceError\u001b[0m: [ShapeInferenceError] Inferred shape and existing shape differ in dimension 0: (400) vs (120)"
          ]
        }
      ]
    }
  ]
}